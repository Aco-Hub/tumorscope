{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ce1d21",
   "metadata": {},
   "source": [
    "# Segmenting with Cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65379ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import core, utils, io, models, metrics\n",
    "from tifffile import imread, imwrite\n",
    "from pathlib import Path\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import napari\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcee7c7",
   "metadata": {},
   "source": [
    "Below we load the videos and extract the channels.\n",
    "\n",
    "Currently this assumes there are 4 channels present :\n",
    "- Channel 1: CSFE (pan-cell marker) \n",
    "  - Tumor cells\n",
    "  - T cells (slightly)\n",
    "- Channel 2: Actin + tubulin channel + NucView (caspace-3 marker)\n",
    "  - T cells centrosomes (bright)\n",
    "  - Dying tumor cells nuclei (bright, may be due to cross-talk with NucView) \n",
    "  - Membrane of T cells and tumor cells (slightly)\n",
    "- Channel 3 : Calcium channel\n",
    "  - Highlights active T cells very brightly\n",
    "  - Only every 10 frames due to phototoxicity\n",
    "- Channel 4 : Brightfield channel\n",
    "  - Currently unused\n",
    "\n",
    "```{note}\n",
    "Change the `Ã¬mage_path` to load a different video.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab84a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 1412, 1412)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = Path(\"../DATA/series003_cCAR_tumor.tif\")\n",
    "\n",
    "image = imread(image_path)\n",
    "image_actin_channel = image[:, 1, ...]\n",
    "image_calcium_channel = image[:, 2, ...]\n",
    "image = image[:, 0, ...]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6772150",
   "metadata": {},
   "source": [
    "### Resizing the image\n",
    "\n",
    "Below we downsample the images by a factor of two. This speeds up the segmentation greatly while only having a small cost on precision, as labels can be upsampled later again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2971aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized =  resize(image, (image.shape[0], image.shape[1] // 2, image.shape[2] // 2), anti_aliasing=True)\n",
    "image_actin_resized = resize(image_actin_channel, (image_actin_channel.shape[0], image_actin_channel.shape[1] // 2, image_actin_channel.shape[2] // 2), anti_aliasing=True)\n",
    "image_calcium_resized = resize(image_calcium_channel, (image_calcium_channel.shape[0], image_calcium_channel.shape[1] // 2, image_calcium_channel.shape[2] // 2), anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3421ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cyril\\anaconda3\\envs\\napari-cellpose\\lib\\site-packages\\napari_tools_menu\\__init__.py:194: FutureWarning: Public access to Window.qt_viewer is deprecated and will be removed in\n",
      "v0.5.0. It is considered an \"implementation detail\" of the napari\n",
      "application, not part of the napari viewer model. If your use case\n",
      "requires access to qt_viewer, please open an issue to discuss.\n",
      "  self.tools_menu = ToolsMenu(self, self.qt_viewer.viewer)\n"
     ]
    }
   ],
   "source": [
    "# v = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'calcium' at 0x1a1a6a994f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v.add_image(image_resized, name=\"image\", colormap=\"viridis\")\n",
    "# v.add_image(image_actin_resized, name=\"actin\", colormap=\"magma\")\n",
    "# v.add_image(image_calcium_resized, name=\"calcium\", colormap=\"turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffe893",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "### Loading the model\n",
    "\n",
    "```{note}\n",
    "For segmenting cells as marked by CSFE, it is recommended to use the `cyto3` model. Other models are available for various modalities however.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233ad80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cyril\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "cellpose_model = models.CellposeModel(gpu=False, model_type='cyto3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e90c58",
   "metadata": {},
   "source": [
    "Below is the code for Cellpose inference. We use `channels=[0,0]`, which must be used when segmenting grayscale images.\n",
    "\n",
    "```{important}\n",
    "The main parameters in CellPose inference are :\n",
    "\n",
    "- `diameter` : The diameter of the cells in pixels. This is used to initialize the model. This is especially crucial, using napari you can use View > Scale bar to measure the diameter of the cells in pixels. The default is 30, for the current data (downsampled by 2), we find 45 to be a good value.\n",
    "- `flow_threshold` : The threshold for the flow field. This is used to determine if a cell is present or not. The default is 0.4, but this can be adjusted based on the data. A lower value will result in more cells being detected, but also more false positives.\n",
    "- `cellprob_threshold` : The threshold for the cell probability. This is used to filter out low-confidence detections. The default is 0.0, but increasing this value can help reduce false positives. Note that the range of values is [-8, 8], unlike many thresholds in image processing where the range is [0, 1].\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aebc1cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46357aa94f0045e39c1cf4db239e22ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks = np.zeros_like(image_resized, dtype=np.uint16)\n",
    "for i in tqdm(range(image_resized.shape[0])):\n",
    "    if i != 50:\n",
    "        break\n",
    "    masks[i], flows, styles = cellpose_model.eval(\n",
    "        image_resized[i], diameter=45, do_3D=False, channels=[0, 0], normalize=True, flow_threshold=0.8, cellprob_threshold=-1.0\n",
    "    )\n",
    "masks = masks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1265a",
   "metadata": {},
   "source": [
    "## Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imwrite(\"./results\", masks.astype(np.uint16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
